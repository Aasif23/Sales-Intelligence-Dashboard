{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8fd82981-dc68-490c-8a64-89ce3f65ea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "Requirement already satisfied: pyspark in /opt/anaconda3/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: kagglehub in /opt/anaconda3/lib/python3.10/site-packages (0.3.12)\n",
      "Requirement already satisfied: sqlalchemy in /opt/anaconda3/lib/python3.10/site-packages (2.0.39)\n",
      "Requirement already satisfied: ipywidgets in /opt/anaconda3/lib/python3.10/site-packages (7.8.5)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in /opt/anaconda3/lib/python3.10/site-packages (from pyspark) (0.10.9.9)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/anaconda3/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.10/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.10/site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.10/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.10/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/lib/python3.10/site-packages (from sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/anaconda3/lib/python3.10/site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/anaconda3/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython_genutils~=0.2.0 in /opt/anaconda3/lib/python3.10/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.10 in /opt/anaconda3/lib/python3.10/site-packages (from ipywidgets) (3.6.10)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/anaconda3/lib/python3.10/site-packages (from ipywidgets) (8.30.0)\n",
      "Requirement already satisfied: jupyterlab_widgets<3,>=1.0.0 in /opt/anaconda3/lib/python3.10/site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/anaconda3/lib/python3.10/site-packages (from widgetsnbextension~=3.6.10->ipywidgets) (7.3.2)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/anaconda3/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/lib/python3.10/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/lib/python3.10/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/anaconda3/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /opt/anaconda3/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.4,>=4.3.4 in /opt/anaconda3/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (4.3.4)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /opt/anaconda3/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /opt/anaconda3/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (6.4.2)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (4.7.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (3.1.6)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.21.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (26.2.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/anaconda3/lib/python3.10/site-packages (from jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /opt/anaconda3/lib/python3.10/site-packages (from jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.27.0)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in /opt/anaconda3/lib/python3.10/site-packages (from jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (6.29.5)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/anaconda3/lib/python3.10/site-packages (from jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (2.2.5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/anaconda3/lib/python3.10/site-packages (from jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (78.1.1)\n",
      "Requirement already satisfied: tomli>=1.2.2 in /opt/anaconda3/lib/python3.10/site-packages (from jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/anaconda3/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (2.16.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/anaconda3/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/anaconda3/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (4.23.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/anaconda3/lib/python3.10/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.14.0)\n",
      "Requirement already satisfied: appnope in /opt/anaconda3/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/anaconda3/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (1.8.11)\n",
      "Requirement already satisfied: nest-asyncio in /opt/anaconda3/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (1.6.0)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.10/site-packages (from ipykernel>=6.5.0->jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.10/site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.22.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (4.3.7)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (3.2.1)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/anaconda3/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /opt/anaconda3/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/anaconda3/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/anaconda3/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (2.1)\n",
      "Requirement already satisfied: uri-template in /opt/anaconda3/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/anaconda3/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/anaconda3/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/anaconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/anaconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/anaconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (3.1.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/anaconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/anaconda3/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/lib/python3.10/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.10/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (0.5.1)\n",
      "\u001b[33mWARNING: bleach 4.1.0 does not provide the extra 'css'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: fastjsonschema>=2.15 in /opt/anaconda3/lib/python3.10/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (2.20.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/lib/python3.10/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.10/site-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.10/site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/anaconda3/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (2.21)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (2.5)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/anaconda3/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: executing in /opt/anaconda3/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/anaconda3/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/lib/python3.10/site-packages (from stack-data->ipython>=4.0.0->ipywidgets) (0.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyspark pandas kagglehub sqlalchemy ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3e414b41-537e-42c3-83dd-43594f61bb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, avg, month, year, to_date, lit, round, desc, to_timestamp, greatest # Added greatest here\n",
    "from pyspark.sql.types import DoubleType, StringType, IntegerType, DateType, StructType, StructField\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "import sqlite3\n",
    "import logging\n",
    "\n",
    "# Configure logging for better visibility in the notebook\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Global Constants\n",
    "KAGGLE_DATASET_REF = \"kyanyoga/sample-sales-data\"\n",
    "CSV_FILE_NAME = \"sales_data_sample.csv\"\n",
    "DB_NAME = \"sales_analytics.db\"\n",
    "PARQUET_OUTPUT_DIR = \"output/parquet\"\n",
    "SALES_THRESHOLD = 5000\n",
    "PROFIT_MARGIN_RATE = 0.30 # 30% profit margin assumed for calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7e40bb5a-7425-471f-b6fb-f9d3fcc2ea0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-22 23:33:04,098 - INFO - Initializing Spark Session...\n",
      "2025-06-22 23:33:04,145 - INFO - Spark Session initialized.\n"
     ]
    }
   ],
   "source": [
    "def initialize_spark_session():\n",
    "    \"\"\"Initializes and returns a SparkSession.\"\"\"\n",
    "    logging.info(\"Initializing Spark Session...\")\n",
    "    spark = (\n",
    "        SparkSession.builder.appName(\"SalesAnalyticsPipeline\")\n",
    "        .config(\"spark.memory.offHeap.enabled\", \"true\")\n",
    "        .config(\"spark.memory.offHeap.size\", \"2g\")\n",
    "        .config(\"spark.driver.memory\", \"4g\") # Increased driver memory to 4GB\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    logging.info(\"Spark Session initialized.\")\n",
    "    return spark\n",
    "\n",
    "spark = initialize_spark_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "08529a16-5cec-4868-9aa4-00e916b3bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_schema():\n",
    "    \"\"\"Defines the explicit schema for the sales data.\"\"\"\n",
    "    logging.info(\"Defining explicit schema for the sales data.\")\n",
    "    schema = StructType([\n",
    "        StructField(\"ORDERNUMBER\", IntegerType(), True),\n",
    "        StructField(\"QUANTITYORDERED\", IntegerType(), True),\n",
    "        StructField(\"PRICEEACH\", DoubleType(), True),\n",
    "        StructField(\"ORDERLINENUMBER\", IntegerType(), True),\n",
    "        StructField(\"SALES\", DoubleType(), True),\n",
    "        StructField(\"ORDERDATE\", StringType(), True),\n",
    "        StructField(\"STATUS\", StringType(), True),\n",
    "        StructField(\"QTR_ID\", IntegerType(), True),\n",
    "        StructField(\"MONTH_ID\", IntegerType(), True),\n",
    "        StructField(\"YEAR_ID\", IntegerType(), True),\n",
    "        StructField(\"PRODUCTLINE\", StringType(), True),\n",
    "        StructField(\"MSRP\", IntegerType(), True),\n",
    "        StructField(\"PRODUCTCODE\", StringType(), True),\n",
    "        StructField(\"CUSTOMERNAME\", StringType(), True),\n",
    "        StructField(\"PHONE\", StringType(), True),\n",
    "        StructField(\"ADDRESSLINE1\", StringType(), True),\n",
    "        StructField(\"ADDRESSLINE2\", StringType(), True),\n",
    "        StructField(\"CITY\", StringType(), True),\n",
    "        StructField(\"STATE\", StringType(), True),\n",
    "        StructField(\"POSTALCODE\", StringType(), True),\n",
    "        StructField(\"COUNTRY\", StringType(), True),\n",
    "        StructField(\"TERRITORY\", StringType(), True),\n",
    "        StructField(\"CONTACTLASTNAME\", StringType(), True),\n",
    "        StructField(\"CONTACTFIRSTNAME\", StringType(), True),\n",
    "        StructField(\"DEALSIZE\", StringType(), True)\n",
    "\n",
    "    ])\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb94a99-0f5d-48fd-a150-e2ba1c337228",
   "metadata": {},
   "source": [
    "def ingest_data(spark_session, kaggle_dataset_ref, csv_file_name, schema):\n",
    "    \"\"\"\n",
    "    Loads raw CSV data from KaggleHub into a PySpark DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        spark_session: The active SparkSession.\n",
    "        kaggle_dataset_ref (str): Kaggle dataset reference.\n",
    "        csv_file_name (str): The name of the CSV file within the dataset.\n",
    "        schema: The explicit schema to apply.\n",
    "        \n",
    "    Returns:\n",
    "        pyspark.sql.DataFrame: The raw PySpark DataFrame.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Attempting to load dataset '{csv_file_name}' from KaggleHub...\")\n",
    "    try:\n",
    "        pandas_df = kagglehub.load_dataset(\n",
    "            KaggleDatasetAdapter.PANDAS,\n",
    "            kaggle_dataset_ref,\n",
    "            csv_file_name,\n",
    "            # IMPORTANT: Specify encoding to handle potential UnicodeDecodeError\n",
    "            pandas_kwargs={\"encoding\": \"latin1\"} \n",
    "        )\n",
    "        logging.info(\"Dataset loaded successfully into Pandas DataFrame.\")\n",
    "\n",
    "        # Convert Pandas DataFrame to PySpark DataFrame with the explicit schema\n",
    "        raw_df = spark_session.createDataFrame(pandas_df, schema=schema)\n",
    "        logging.info(\"Converted Pandas DataFrame to PySpark DataFrame with explicit schema.\")\n",
    "        return raw_df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading dataset from KaggleHub: {e}\", exc_info=True)\n",
    "        raise\n",
    "\n",
    "raw_df = ingest_data(spark, KAGGLE_DATASET_REF, CSV_FILE_NAME, define_schema())\n",
    "raw_df.show(5)\n",
    "raw_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "68f06517-c701-4d12-8c96-3a213063ccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-22 23:33:07,022 - INFO - Starting data cleaning and validation...\n",
      "2025-06-22 23:33:23,485 - INFO - Checking for and removing duplicate records... \n",
      "2025-06-22 23:33:24,947 - INFO - No duplicate rows found.                       \n",
      "2025-06-22 23:33:26,127 - INFO - Filtered out records with invalid dates or critical missing/invalid numeric values. Remaining records: 2823\n",
      "2025-06-22 23:33:26,131 - INFO - Calculating 'DISCOUNT' column from 'SALES', 'QUANTITYORDERED', and 'MSRP'.\n",
      "2025-06-22 23:33:26,183 - WARNING - 'COMMISSION' column not found. Adding with default value 0.0.\n",
      "2025-06-22 23:33:26,198 - INFO - Adding 'Profit' column with assumed profit margin rate of 30.0%.\n",
      "2025-06-22 23:33:26,227 - INFO - Data cleaning and validation complete. Added 'Profit' and calculated 'DISCOUNT' column.\n",
      "2025-06-22 23:33:26,269 - INFO - Cleaned DataFrame cached.\n",
      "[Stage 96:==================================================>   (188 + 4) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+-------+------------+---------------+---------+-------+--------+----+-----------+--------------------+------------+--------------------+------------+------------+-----+----------+---------+---------+---------------+----------------+------+--------+-------+---------------+-------------------+----------+-----------------+\n",
      "|OrderNumber| OrderDate| Status| ProductLine|QuantityOrdered|PriceEach|  Sales|DealSize|MSRP|ProductCode|        CustomerName|       Phone|        AddressLine1|AddressLine2|        City|State|PostalCode|  Country|Territory|ContactLastName|ContactFirstName|QTR_ID|MONTH_ID|YEAR_ID|OrderLineNumber|           DISCOUNT|COMMISSION|           Profit|\n",
      "+-----------+----------+-------+------------+---------------+---------+-------+--------+----+-----------+--------------------+------------+--------------------+------------+------------+-----+----------+---------+---------+---------------+----------------+------+--------+-------+---------------+-------------------+----------+-----------------+\n",
      "|      10107|2003-02-24|Shipped| Motorcycles|             30|     95.7| 2871.0|   Small|  95|   S10_1678|   Land of Toys Inc.|  2125557818|897 Long Airport ...|         NaN|         NYC|   NY|     10022|      USA|      NaN|             Yu|            Kwai|     1|       2|   2003|              2|                0.0|       0.0|            861.3|\n",
      "|      10122|2003-05-08|Shipped| Motorcycles|             31|    44.66|1384.46|   Small|  40|   S32_2206|Marseille Mini Autos|  91.24.4555|12, rue des Bouchers|         NaN|   Marseille|  NaN|     13008|   France|     EMEA|        Lebihan|        Laurence|     2|       5|   2003|             17|                0.0|       0.0|          415.338|\n",
      "|      10124|2003-05-21|Shipped|Vintage Cars|             42|    53.88|2262.96|   Small|  60|   S18_2248|  Signal Gift Stores|  7025551838|     8489 Strong St.|         NaN|   Las Vegas|   NV|     83030|      USA|      NaN|           King|             Sue|     2|       5|   2003|              5|0.10199999999999998|       0.0|       609.641424|\n",
      "|      10148|2003-09-11|Shipped|Classic Cars|             21|     73.6| 1545.6|   Small|  90|   S24_2766|Anna's Decoration...|02 9936 8555|   201 Miller Street|    Level 15|North Sydney|  NSW|      2060|Australia|     APAC|         O'Hara|            Anna|     3|       9|   2003|              4|0.18222222222222229|       0.0|379.1871999999999|\n",
      "|      10160|2003-10-11|Shipped|Classic Cars|             42|     37.0| 1554.0|   Small|  37|   S24_2972|Men 'R' US Retail...|  2155554369|    6047 Douglas Av.|         NaN| Los Angeles|   CA|       NaN|      USA|      NaN|       Chandler|         Michael|     4|      10|   2003|              2|                0.0|       0.0|            466.2|\n",
      "+-----------+----------+-------+------------+---------------+---------+-------+--------+----+-----------+--------------------+------------+--------------------+------------+------------+-----+----------+---------+---------+---------------+----------------+------+--------+-------+---------------+-------------------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "root\n",
      " |-- OrderNumber: integer (nullable = true)\n",
      " |-- OrderDate: date (nullable = true)\n",
      " |-- Status: string (nullable = false)\n",
      " |-- ProductLine: string (nullable = false)\n",
      " |-- QuantityOrdered: integer (nullable = true)\n",
      " |-- PriceEach: double (nullable = false)\n",
      " |-- Sales: double (nullable = false)\n",
      " |-- DealSize: string (nullable = false)\n",
      " |-- MSRP: integer (nullable = true)\n",
      " |-- ProductCode: string (nullable = false)\n",
      " |-- CustomerName: string (nullable = false)\n",
      " |-- Phone: string (nullable = false)\n",
      " |-- AddressLine1: string (nullable = false)\n",
      " |-- AddressLine2: string (nullable = false)\n",
      " |-- City: string (nullable = false)\n",
      " |-- State: string (nullable = false)\n",
      " |-- PostalCode: string (nullable = false)\n",
      " |-- Country: string (nullable = false)\n",
      " |-- Territory: string (nullable = false)\n",
      " |-- ContactLastName: string (nullable = false)\n",
      " |-- ContactFirstName: string (nullable = false)\n",
      " |-- QTR_ID: integer (nullable = true)\n",
      " |-- MONTH_ID: integer (nullable = true)\n",
      " |-- YEAR_ID: integer (nullable = true)\n",
      " |-- OrderLineNumber: integer (nullable = true)\n",
      " |-- DISCOUNT: double (nullable = false)\n",
      " |-- COMMISSION: double (nullable = false)\n",
      " |-- Profit: double (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "def clean_and_validate_data(raw_df, profit_margin_rate):\n",
    "    \"\"\"\n",
    "    Performs data cleaning, validation, and enriches the DataFrame.\n",
    "    \"\"\"\n",
    "    logging.info(\"Starting data cleaning and validation...\")\n",
    "\n",
    "    # Drop columns that are entirely null (e.g., if a column was added but always empty)\n",
    "    null_columns_check = [c for c, count in raw_df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in raw_df.columns]).collect()[0].asDict().items() if count == raw_df.count()]\n",
    "    if null_columns_check:\n",
    "        logging.info(f\"Dropping entirely null columns: {null_columns_check}\")\n",
    "        raw_df = raw_df.drop(*null_columns_check)\n",
    "    \n",
    "    # Select and cast columns\n",
    "    cleaned_df = raw_df.select(\n",
    "        col(\"ORDERNUMBER\").cast(IntegerType()).alias(\"OrderNumber\"),\n",
    "        to_timestamp(col(\"ORDERDATE\"), \"M/d/yyyy H:mm\").cast(DateType()).alias(\"OrderDate\"),\n",
    "        col(\"STATUS\").cast(StringType()).alias(\"Status\"),\n",
    "        col(\"PRODUCTLINE\").cast(StringType()).alias(\"ProductLine\"),\n",
    "        col(\"QUANTITYORDERED\").cast(IntegerType()).alias(\"QuantityOrdered\"),\n",
    "        col(\"PRICEEACH\").cast(DoubleType()).alias(\"PriceEach\"),\n",
    "        col(\"SALES\").cast(DoubleType()).alias(\"Sales\"),\n",
    "        col(\"DEALSIZE\").cast(StringType()).alias(\"DealSize\"),\n",
    "        col(\"MSRP\").cast(IntegerType()).alias(\"MSRP\"),\n",
    "        col(\"PRODUCTCODE\").cast(StringType()).alias(\"ProductCode\"),\n",
    "        col(\"CUSTOMERNAME\").cast(StringType()).alias(\"CustomerName\"),\n",
    "        col(\"PHONE\").cast(StringType()).alias(\"Phone\"),\n",
    "        col(\"ADDRESSLINE1\").cast(StringType()).alias(\"AddressLine1\"),\n",
    "        col(\"ADDRESSLINE2\").cast(StringType()).alias(\"AddressLine2\"),\n",
    "        col(\"CITY\").cast(StringType()).alias(\"City\"),\n",
    "        col(\"STATE\").cast(StringType()).alias(\"State\"),\n",
    "        col(\"POSTALCODE\").cast(StringType()).alias(\"PostalCode\"),\n",
    "        col(\"COUNTRY\").cast(StringType()).alias(\"Country\"),\n",
    "        col(\"TERRITORY\").cast(StringType()).alias(\"Territory\"),\n",
    "        col(\"CONTACTLASTNAME\").cast(StringType()).alias(\"ContactLastName\"),\n",
    "        col(\"CONTACTFIRSTNAME\").cast(StringType()).alias(\"ContactFirstName\"),\n",
    "        col(\"QTR_ID\").cast(IntegerType()).alias(\"QTR_ID\"),\n",
    "        col(\"MONTH_ID\").cast(IntegerType()).alias(\"MONTH_ID\"),\n",
    "        col(\"YEAR_ID\").cast(IntegerType()).alias(\"YEAR_ID\"),\n",
    "        col(\"ORDERLINENUMBER\").cast(IntegerType()).alias(\"OrderLineNumber\")\n",
    "    )\n",
    "\n",
    "    # Fill missing numeric values with 0 and string values with 'N/A'\n",
    "    numeric_cols = [\"QuantityOrdered\", \"PriceEach\", \"Sales\", \"MSRP\", \"QTR_ID\", \"MONTH_ID\", \"YEAR_ID\", \"OrderLineNumber\"]\n",
    "    string_cols = [\"Status\", \"ProductLine\", \"DealSize\", \"CustomerName\", \"Phone\", \"AddressLine1\",\n",
    "                   \"AddressLine2\", \"City\", \"State\", \"PostalCode\", \"Country\", \"Territory\",\n",
    "                   \"ContactLastName\", \"ContactFirstName\", \"ProductCode\"]\n",
    "\n",
    "    for col_name in numeric_cols:\n",
    "        if col_name in cleaned_df.columns:\n",
    "            cleaned_df = cleaned_df.na.fill(0, subset=[col_name])\n",
    "\n",
    "    for col_name in string_cols:\n",
    "        if col_name in cleaned_df.columns:\n",
    "            cleaned_df = cleaned_df.na.fill(\"N/A\", subset=[col_name])\n",
    "            \n",
    "    logging.info(\"Checking for and removing duplicate records...\")\n",
    "    initial_row_count = cleaned_df.count()\n",
    "    cleaned_df = cleaned_df.dropDuplicates([\"OrderNumber\", \"OrderLineNumber\", \"ProductCode\"])\n",
    "    deduplicated_row_count = cleaned_df.count()\n",
    "    if initial_row_count != deduplicated_row_count:\n",
    "        logging.info(f\"Removed {initial_row_count - deduplicated_row_count} duplicate rows.\")\n",
    "    else:\n",
    "        logging.info(\"No duplicate rows found.\")\n",
    "\n",
    "    # Filter out records with invalid dates or critical missing/invalid numeric values\n",
    "    cleaned_df = cleaned_df.filter(\n",
    "        (col(\"OrderDate\").isNotNull()) &\n",
    "        (col(\"Sales\").isNotNull()) & (col(\"Sales\") >= 0) &\n",
    "        (col(\"QuantityOrdered\").isNotNull()) & (col(\"QuantityOrdered\") > 0) &\n",
    "        (col(\"MSRP\").isNotNull()) & (col(\"MSRP\") > 0) # MSRP must be positive for discount calculation\n",
    "    )\n",
    "    logging.info(f\"Filtered out records with invalid dates or critical missing/invalid numeric values. Remaining records: {cleaned_df.count()}\")\n",
    "\n",
    "    # Dynamically add and calculate 'DISCOUNT' and 'COMMISSION' if not present\n",
    "    if \"DISCOUNT\" not in cleaned_df.columns:\n",
    "        logging.info(\"Calculating 'DISCOUNT' column from 'SALES', 'QUANTITYORDERED', and 'MSRP'.\")\n",
    "        # Calculate discount: 1 - (actual_price_per_unit / msrp)\n",
    "        # Add a check to avoid division by zero and handle cases where sales might be higher than MSRP implies\n",
    "        # Use greatest to ensure discount is not negative\n",
    "        cleaned_df = cleaned_df.withColumn(\n",
    "            \"DISCOUNT\",\n",
    "            lit(1) - (col(\"SALES\") / (col(\"QUANTITYORDERED\") * col(\"MSRP\")))\n",
    "        ).withColumn(\n",
    "            \"DISCOUNT\",\n",
    "            # Cap discount at 0 if the calculated value is negative (meaning sales price was higher than MSRP)\n",
    "            (col(\"DISCOUNT\")).cast(DoubleType())\n",
    "        )\n",
    "        # Ensure discount is not less than 0, as a negative discount doesn't make sense in this context.\n",
    "        cleaned_df = cleaned_df.withColumn(\"DISCOUNT\", greatest(lit(0.0), col(\"DISCOUNT\")))\n",
    "        \n",
    "    if \"COMMISSION\" not in cleaned_df.columns:\n",
    "        logging.warning(\"'COMMISSION' column not found. Adding with default value 0.0.\")\n",
    "        cleaned_df = cleaned_df.withColumn(\"COMMISSION\", lit(0.0).cast(DoubleType()))\n",
    "\n",
    "    logging.info(f\"Adding 'Profit' column with assumed profit margin rate of {profit_margin_rate * 100}%.\")\n",
    "    # Profit calculation now uses the newly derived DISCOUNT\n",
    "    cleaned_df = cleaned_df.withColumn(\"Profit\", col(\"Sales\") * (1 - col(\"DISCOUNT\")) * lit(profit_margin_rate))\n",
    "    \n",
    "    logging.info(\"Data cleaning and validation complete. Added 'Profit' and calculated 'DISCOUNT' column.\")\n",
    "\n",
    "    cleaned_df.cache()\n",
    "    logging.info(\"Cleaned DataFrame cached.\")\n",
    "    return cleaned_df\n",
    "\n",
    "cleaned_df = clean_and_validate_data(raw_df, PROFIT_MARGIN_RATE)\n",
    "cleaned_df.show(5)\n",
    "cleaned_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ebfe607-ce0a-440e-8e41-fcf98bdda597",
   "metadata": {},
   "source": [
    "def generate_aggregations(cleaned_df):\n",
    "    \"\"\"\n",
    "    Generates meaningful aggregations from the cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    logging.info(\"Starting generation of meaningful aggregations...\")\n",
    "\n",
    "    # 5.1. Monthly sales by region\n",
    "    logging.info(\"Calculating Monthly Sales by Region...\")\n",
    "    monthly_sales_by_region = cleaned_df.withColumn(\"SalesMonth\", month(col(\"OrderDate\"))) \\\n",
    "                                        .withColumn(\"SalesYear\", year(col(\"OrderDate\"))) \\\n",
    "                                        .groupBy(\"SalesYear\", \"SalesMonth\", \"Country\") \\\n",
    "                                        .agg(round(sum(\"Sales\"), 2).alias(\"TotalSales\")) \\\n",
    "                                        .orderBy(\"SalesYear\", \"SalesMonth\", desc(\"TotalSales\"))\n",
    "    monthly_sales_by_region.show(10)\n",
    "    logging.info(\"Monthly Sales by Region calculated.\")\n",
    "\n",
    "    # 5.2. Top 10 customers by profit\n",
    "    logging.info(\"Calculating Top 10 Customers by Profit...\")\n",
    "    top_10_customers_by_profit = cleaned_df.groupBy(\"CustomerName\") \\\n",
    "                                           .agg(round(sum(\"Profit\"), 2).alias(\"TotalProfit\")) \\\n",
    "                                           .orderBy(desc(\"TotalProfit\")) \\\n",
    "                                           .limit(10)\n",
    "    top_10_customers_by_profit.show()\n",
    "    logging.info(\"Top 10 Customers by Profit calculated.\")\n",
    "\n",
    "    # 5.3. Category-wise average discount (ProductLine is a good proxy for Category)\n",
    "    logging.info(\"Calculating Category-wise Average Discount...\")\n",
    "    category_wise_avg_discount = cleaned_df.groupBy(\"ProductLine\") \\\n",
    "                                           .agg(round(avg(\"DISCOUNT\"), 4).alias(\"AverageDiscount\")) \\\n",
    "                                           .orderBy(desc(\"AverageDiscount\"))\n",
    "    category_wise_avg_discount.show()\n",
    "    logging.info(\"Category-wise Average Discount calculated.\")\n",
    "\n",
    "    return {\n",
    "        \"monthly_sales_by_region\": monthly_sales_by_region,\n",
    "        \"top_10_customers_by_profit\": top_10_customers_by_profit,\n",
    "        \"category_wise_avg_discount\": category_wise_avg_discount\n",
    "    }\n",
    "\n",
    "aggregations = generate_aggregations(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3f380354-f22c-45e7-a421-0c1d6f5d916c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-22 23:33:40,217 - INFO - Starting execution of reporting queries...\n",
      "2025-06-22 23:33:40,233 - INFO - Cleaned data registered as temporary view 'sales_data' for Spark SQL.\n",
      "2025-06-22 23:33:40,238 - INFO - Running Reporting Query: Sales > 5000...\n",
      "2025-06-22 23:33:41,249 - INFO - Sales above 5000 query executed.               \n",
      "2025-06-22 23:33:41,250 - INFO - Running Reporting Query: Profitable Categories...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------------+------------+-------+\n",
      "|OrderNumber| OrderDate|        CustomerName| ProductLine|  Sales|\n",
      "+-----------+----------+--------------------+------------+-------+\n",
      "|      10407|2005-04-22|The Sharp Gifts W...|Vintage Cars|14082.8|\n",
      "|      10322|2004-11-04|Online Diecast Cr...|Vintage Cars|12536.5|\n",
      "|      10424|2005-05-31|Euro Shopping Cha...|Classic Cars|12001.0|\n",
      "|      10412|2005-05-03|Euro Shopping Cha...|Classic Cars|11887.8|\n",
      "|      10403|2005-04-08|UK Collectables, ...| Motorcycles|11886.6|\n",
      "|      10405|2005-04-14|         Mini Caravy|Classic Cars|11739.7|\n",
      "|      10312|2004-10-21|Mini Gifts Distri...|Classic Cars|11623.7|\n",
      "|      10333|2004-11-18|     Mini Wheels Co.|Vintage Cars|11336.7|\n",
      "|      10127|2003-06-03|  Muscle Machine Inc|Classic Cars|11279.2|\n",
      "|      10150|2003-09-19|Dragon Souveniers...|Classic Cars|10993.5|\n",
      "+-----------+----------+--------------------+------------+-------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-22 23:33:43,867 - INFO - Profitable Categories query executed.          \n",
      "2025-06-22 23:33:43,868 - INFO - Running Reporting Query: Customers with High Discount Usage...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+\n",
      "|     ProductLine|TotalProfit|\n",
      "+----------------+-----------+\n",
      "|    Classic Cars| 1096862.82|\n",
      "|    Vintage Cars|  543582.78|\n",
      "|     Motorcycles|   333088.1|\n",
      "|Trucks and Buses|  321266.23|\n",
      "|          Planes|  277960.61|\n",
      "|           Ships|  204820.59|\n",
      "|          Trains|   65606.82|\n",
      "+----------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-22 23:33:46,714 - INFO - Customers with High Discount Usage query executed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+----------+\n",
      "|        CustomerName|AverageDiscountUsed|TotalSales|\n",
      "+--------------------+-------------------+----------+\n",
      "|     Lyon Souveniers|              0.146|  78570.34|\n",
      "|Anna's Decoration...|             0.1372| 153996.13|\n",
      "|Motor Mint Distri...|             0.1343|  83682.16|\n",
      "|  Reims Collectables|             0.1215| 135042.94|\n",
      "|     Vitachrome Inc.|             0.1212|  88041.26|\n",
      "|   Toys4GrownUps.com|             0.1205| 104561.96|\n",
      "|      AV Stores, Co.|             0.1163| 157807.81|\n",
      "| Suominen Souveniers|             0.1111| 113961.15|\n",
      "|  Baane Mini Imports|             0.1085| 116599.19|\n",
      "|  Signal Gift Stores|             0.1049|  82751.08|\n",
      "+--------------------+-------------------+----------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "def run_reporting_queries(cleaned_df, sales_threshold):\n",
    "    \"\"\"\n",
    "    Runs reporting queries using Spark SQL on the cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    logging.info(\"Starting execution of reporting queries...\")\n",
    "\n",
    "    # Register the cleaned DataFrame as a temporary SQL view\n",
    "    cleaned_df.createOrReplaceTempView(\"sales_data\")\n",
    "    logging.info(\"Cleaned data registered as temporary view 'sales_data' for Spark SQL.\")\n",
    "\n",
    "    # 6.1. Sales greater than a threshold\n",
    "    logging.info(f\"Running Reporting Query: Sales > {sales_threshold}...\")\n",
    "    sales_above_threshold = spark.sql(f\"\"\"\n",
    "        SELECT\n",
    "            OrderNumber,\n",
    "            OrderDate,\n",
    "            CustomerName,\n",
    "            ProductLine,\n",
    "            Sales\n",
    "        FROM\n",
    "            sales_data\n",
    "        WHERE\n",
    "            Sales > {sales_threshold}\n",
    "        ORDER BY\n",
    "            Sales DESC\n",
    "    \"\"\")\n",
    "    sales_above_threshold.show(10)\n",
    "    logging.info(f\"Sales above {sales_threshold} query executed.\")\n",
    "\n",
    "    # 6.2. Profitable categories (ProductLine as Category) - having total profit > 0\n",
    "    logging.info(\"Running Reporting Query: Profitable Categories...\")\n",
    "    profitable_categories = spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            ProductLine,\n",
    "            ROUND(SUM(Profit), 2) AS TotalProfit\n",
    "        FROM\n",
    "            sales_data\n",
    "        GROUP BY\n",
    "            ProductLine\n",
    "        HAVING\n",
    "            SUM(Profit) > 0\n",
    "        ORDER BY\n",
    "            TotalProfit DESC\n",
    "    \"\"\")\n",
    "    profitable_categories.show()\n",
    "    logging.info(\"Profitable Categories query executed.\")\n",
    "\n",
    "    # 6.3. Customers with high discount usage (e.g., avg discount > 0.10)\n",
    "    logging.info(\"Running Reporting Query: Customers with High Discount Usage...\")\n",
    "    customers_high_discount = spark.sql(\"\"\"\n",
    "        SELECT\n",
    "            CustomerName,\n",
    "            ROUND(AVG(DISCOUNT), 4) AS AverageDiscountUsed,\n",
    "            ROUND(SUM(Sales), 2) AS TotalSales\n",
    "        FROM\n",
    "            sales_data\n",
    "        GROUP BY\n",
    "            CustomerName\n",
    "        HAVING\n",
    "            AVG(DISCOUNT) > 0.10\n",
    "        ORDER BY\n",
    "            AverageDiscountUsed DESC\n",
    "    \"\"\")\n",
    "    customers_high_discount.show(10)\n",
    "    logging.info(\"Customers with High Discount Usage query executed.\")\n",
    "\n",
    "    return {\n",
    "        \"sales_above_threshold\": sales_above_threshold,\n",
    "        \"profitable_categories\": profitable_categories,\n",
    "        \"customers_high_discount\": customers_high_discount\n",
    "    }\n",
    "\n",
    "reporting_queries = run_reporting_queries(cleaned_df, SALES_THRESHOLD)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9959f7ee-6fc3-4bbb-a81f-c28385706e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-22 23:33:46,776 - INFO - Storing transformed outputs to SQLite database: sales_analytics.db...\n",
      "2025-06-22 23:33:46,781 - INFO - Removed existing database file: sales_analytics.db\n",
      "2025-06-22 23:33:46,784 - INFO - Storing 'monthly_sales_by_region' table...\n",
      "2025-06-22 23:33:50,104 - INFO - Stored 'monthly_sales_by_region' table.        \n",
      "2025-06-22 23:33:50,106 - INFO - Storing 'top_10_customers_by_profit' table...\n",
      "2025-06-22 23:33:53,297 - INFO - Stored 'top_10_customers_by_profit' table.     \n",
      "2025-06-22 23:33:53,298 - INFO - Storing 'category_wise_avg_discount' table...\n",
      "2025-06-22 23:33:56,179 - INFO - Stored 'category_wise_avg_discount' table.     \n",
      "2025-06-22 23:33:56,180 - INFO - Storing 'sales_above_threshold' table...\n",
      "2025-06-22 23:33:58,701 - INFO - Stored 'sales_above_threshold' table.          \n",
      "2025-06-22 23:33:58,702 - INFO - Storing 'profitable_categories' table...\n",
      "2025-06-22 23:34:00,604 - INFO - Stored 'profitable_categories' table.          \n",
      "2025-06-22 23:34:00,605 - INFO - Storing 'customers_high_discount' table...\n",
      "2025-06-22 23:34:02,849 - INFO - Stored 'customers_high_discount' table.        \n",
      "2025-06-22 23:34:02,850 - INFO - All transformed outputs stored successfully in SQLite.\n",
      "2025-06-22 23:34:02,851 - INFO - SQLite connection closed.\n",
      "2025-06-22 23:34:02,858 - INFO - Storing transformed outputs as partitioned Parquet files to 'output/parquet'...\n",
      "2025-06-22 23:34:02,860 - INFO - Storing 'monthly_sales_by_region' to Parquet at 'output/parquet/monthly_sales_by_region'...\n",
      "2025-06-22 23:34:05,932 - INFO - Stored 'monthly_sales_by_region' to Parquet successfully.\n",
      "2025-06-22 23:34:05,933 - INFO - Storing 'top_10_customers_by_profit' to Parquet at 'output/parquet/top_10_customers_by_profit'...\n",
      "2025-06-22 23:34:08,423 - INFO - Stored 'top_10_customers_by_profit' to Parquet successfully.\n",
      "2025-06-22 23:34:08,424 - INFO - Storing 'category_wise_avg_discount' to Parquet at 'output/parquet/category_wise_avg_discount'...\n",
      "2025-06-22 23:34:10,737 - INFO - Stored 'category_wise_avg_discount' to Parquet successfully.\n",
      "2025-06-22 23:34:10,739 - INFO - Storing 'sales_above_threshold' to Parquet at 'output/parquet/sales_above_threshold'...\n",
      "2025-06-22 23:34:14,510 - INFO - Stored 'sales_above_threshold' to Parquet successfully.\n",
      "2025-06-22 23:34:14,511 - INFO - Storing 'profitable_categories' to Parquet at 'output/parquet/profitable_categories'...\n",
      "2025-06-22 23:34:16,610 - INFO - Stored 'profitable_categories' to Parquet successfully.\n",
      "2025-06-22 23:34:16,612 - INFO - Storing 'customers_high_discount' to Parquet at 'output/parquet/customers_high_discount'...\n",
      "2025-06-22 23:34:19,144 - INFO - Stored 'customers_high_discount' to Parquet successfully.\n",
      "2025-06-22 23:34:19,145 - INFO - Generating sample JSON data for dashboard preview...\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Combine all DataFrames for storage\n",
    "all_output_dfs = {**aggregations, **reporting_queries}\n",
    "\n",
    "# --- Store to SQLite ---\n",
    "def store_output_to_sqlite(dataframes_to_store, db_name):\n",
    "    \"\"\"\n",
    "    Stores a dictionary of PySpark DataFrames as tables in a local SQLite database.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Storing transformed outputs to SQLite database: {db_name}...\")\n",
    "    if os.path.exists(db_name):\n",
    "        os.remove(db_name)\n",
    "        logging.info(f\"Removed existing database file: {db_name}\")\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_name)\n",
    "        for table_name, df in dataframes_to_store.items():\n",
    "            logging.info(f\"Storing '{table_name}' table...\")\n",
    "            df.toPandas().to_sql(table_name, conn, if_exists=\"replace\", index=False)\n",
    "            logging.info(f\"Stored '{table_name}' table.\")\n",
    "        logging.info(\"All transformed outputs stored successfully in SQLite.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error storing data to SQLite: {e}\", exc_info=True)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            logging.info(\"SQLite connection closed.\")\n",
    "\n",
    "store_output_to_sqlite(all_output_dfs, DB_NAME)\n",
    "\n",
    "# --- Store to Parquet ---\n",
    "def store_output_to_parquet(dataframes_to_store, output_base_path):\n",
    "    \"\"\"\n",
    "    Stores a dictionary of PySpark DataFrames as partitioned Parquet files.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Storing transformed outputs as partitioned Parquet files to '{output_base_path}'...\")\n",
    "    os.makedirs(output_base_path, exist_ok=True)\n",
    "\n",
    "    for table_name, df in dataframes_to_store.items():\n",
    "        output_path = os.path.join(output_base_path, table_name)\n",
    "        logging.info(f\"Storing '{table_name}' to Parquet at '{output_path}'...\")\n",
    "        try:\n",
    "            if \"OrderDate\" in df.columns:\n",
    "                df_with_ym = df.withColumn(\"year\", year(col(\"OrderDate\"))) \\\n",
    "                               .withColumn(\"month\", month(col(\"OrderDate\")))\n",
    "                df_with_ym.write.mode(\"overwrite\").partitionBy(\"year\", \"month\").parquet(output_path)\n",
    "            elif \"SalesYear\" in df.columns and \"SalesMonth\" in df.columns:\n",
    "                df.write.mode(\"overwrite\").partitionBy(\"SalesYear\", \"SalesMonth\").parquet(output_path)\n",
    "            else:\n",
    "                df.write.mode(\"overwrite\").parquet(output_path)\n",
    "            logging.info(f\"Stored '{table_name}' to Parquet successfully.\")\n",
    "        except Exception as e:\n",
    "                logging.error(f\"Error storing '{table_name}' to Parquet: {e}\", exc_info=True)\n",
    "\n",
    "store_output_to_parquet(all_output_dfs, PARQUET_OUTPUT_DIR)\n",
    "\n",
    "# --- Generate Sample JSON for Dashboard (Optional - for web app consumption) ---\n",
    "# For the interactive dashboard, we'll convert a few key dataframes to JSON.\n",
    "# In a real application, a backend API would serve this data.\n",
    "# For this demonstration, we'll simulate by hardcoding a snippet of the JSON data\n",
    "# directly into the React component for quick preview.\n",
    "# However, if you were to deploy this, you'd save these to static files or a database\n",
    "# that your frontend can query.\n",
    "\n",
    "logging.info(\"Generating sample JSON data for dashboard preview...\")\n",
    "# Example: Convert monthly_sales_by_region to JSON\n",
    "monthly_sales_json = aggregations[\"monthly_sales_by_region\"].limit(50).toPandas().to_json(orient=\"records\", indent=2)\n",
    "top_customers_json = aggregations[\"top_10_customers_by_profit\"].toPandas().to_json(orient=\"records\", indent=2)\n",
    "category_discount_json = aggregations[\"category_wise_avg_discount\"].toPandas().to_json(orient=\"records\", indent=2)\n",
    "profitable_categories_json = reporting_queries[\"profitable_categories\"].toPandas().to_json(orient=\"records\", indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fd1dedba-cd22-4967-aadb-f39acfb52843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"SalesYear\":2003,\n",
      "    \"SalesMonth\":1,\n",
      "    \"Country\":\"Norway\",\n",
      "    \"TotalSales\":54702.0\n",
      "  },\n",
      "  {\n",
      "    \"SalesYear\":2003,\n",
      "    \"SalesMonth\":1,\n",
      "    \"Country\":\"Spain\",\n",
      "    \"TotalSales\":44621.96\n",
      "  },\n",
      "  {\n",
      "    \"SalesYear\":2003,\n",
      "    \"SalesMonth\":1,\n",
      "    \"Country\":\"USA\",\n",
      "    \"TotalSales\":18997.3\n",
      "  },\n",
      "  {\n",
      "    \"SalesYear\":2003,\n",
      "    \"SalesMonth\":1,\n",
      "    \"Country\":\"Germany\",\n",
      "    \"TotalSales\":11432.34\n",
      "  },\n",
      "  {\n",
      "    \"SalesYear\":2003,\n",
      "    \"SalesMonth\":2,\n",
      "    \"Country\":\"Denmark\",\n",
      "    \"TotalSales\":58871.11\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(monthly_sales_json[:500]) # Print first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dcb84804-c17a-4d97-9d80-375d23719f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top Customers JSON (Sample) ---\n",
      "[\n",
      "  {\n",
      "    \"CustomerName\":\"Euro Shopping Channel\",\n",
      "    \"TotalProfit\":256053.9\n",
      "  },\n",
      "  {\n",
      "    \"CustomerName\":\"Mini Gifts Distributors Ltd.\",\n",
      "    \"TotalProfit\":184647.06\n",
      "  },\n",
      "  {\n",
      "    \"CustomerName\":\"Australian Collectors, Co.\",\n",
      "    \"TotalProfit\":57478.22\n",
      "  },\n",
      "  {\n",
      "    \"CustomerName\":\"Muscle Machine Inc\",\n",
      "    \"TotalProfit\":57374.35\n",
      "  },\n",
      "  {\n",
      "    \"CustomerName\":\"La Rochelle Gifts\",\n",
      "    \"TotalProfit\":50583.19\n",
      "  },\n",
      "  {\n",
      "    \"CustomerName\":\"Dragon Souveniers, Ltd.\",\n",
      "    \"TotalProfit\":49395.37\n",
      "  },\n",
      "  {\n",
      "    \"CustomerName\":\"Land of Toys Inc.\",\n",
      "    \"TotalProfit\":46048.63\n",
      "  },\n",
      "  {\n",
      "    \"CustomerName\":\"The Sharp Gifts Warehouse\",\n",
      "    \"TotalProfit\":45629.82\n",
      "  },\n",
      "  {\n",
      "    \"CustomerName\":\"AV Stores, Co.\",\n",
      "    \"TotalProfit\":43639.61\n",
      "  },\n",
      "  {\n",
      "    \"CustomerName\":\"Corporate Gift Ideas Co.\",\n",
      "    \"TotalProfit\":43336.81\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Top Customers JSON (Sample) ---\")\n",
    "print(top_customers_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a8fb9298-89a5-49da-a10d-9eae642ed0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Category Discount JSON (Sample) ---\n",
      "[\n",
      "  {\n",
      "    \"ProductLine\":\"Classic Cars\",\n",
      "    \"AverageDiscount\":0.0868\n",
      "  },\n",
      "  {\n",
      "    \"ProductLine\":\"Trucks and Buses\",\n",
      "    \"AverageDiscount\":0.0692\n",
      "  },\n",
      "  {\n",
      "    \"ProductLine\":\"Vintage Cars\",\n",
      "    \"AverageDiscount\":0.0633\n",
      "  },\n",
      "  {\n",
      "    \"ProductLine\":\"Motorcycles\",\n",
      "    \"AverageDiscount\":0.0614\n",
      "  },\n",
      "  {\n",
      "    \"ProductLine\":\"Planes\",\n",
      "    \"AverageDiscount\":0.0614\n",
      "  },\n",
      "  {\n",
      "    \"ProductLine\":\"Ships\",\n",
      "    \"AverageDiscount\":0.0531\n",
      "  },\n",
      "  {\n",
      "    \"ProductLine\":\"Trains\",\n",
      "    \"AverageDiscount\":0.0476\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Category Discount JSON (Sample) ---\")\n",
    "print(category_discount_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5f140f66-14ef-4705-847f-66b1fb352651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Profitable Categories JSON (Sample) ---\n",
      "[\n",
      "  {\n",
      "    \"ProductLine\":\"Classic Cars\",\n",
      "    \"TotalProfit\":1096862.8200000001\n",
      "  },\n",
      "  {\n",
      "    \"ProductLine\":\"Vintage Cars\",\n",
      "    \"TotalProfit\":543582.78\n",
      "  },\n",
      "  {\n",
      "    \"ProductLine\":\"Motorcycles\",\n",
      "    \"TotalProfit\":333088.1\n",
      "  },\n",
      "  {\n",
      "    \"ProductLine\":\"Trucks and Buses\",\n",
      "    \"TotalProfit\":321266.23\n",
      "  },\n",
      "  {\n",
      "    \"ProductLine\":\"Planes\",\n",
      "    \"TotalProfit\":277960.61\n",
      "  },\n",
      "  {\n",
      "    \"ProductLine\":\"Ships\",\n",
      "    \"TotalProfit\":204820.59\n",
      "  },\n",
      "  {\n",
      "    \"ProductLine\":\"Trains\",\n",
      "    \"TotalProfit\":65606.82\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Profitable Categories JSON (Sample) ---\")\n",
    "print(profitable_categories_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "83953e98-94f4-4b00-961b-af41e340106c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-22 23:34:23,601 - INFO - Spark Session stopped.\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "logging.info(\"Spark Session stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
